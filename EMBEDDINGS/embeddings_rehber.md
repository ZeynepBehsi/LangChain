# EMBEDDINGS REHBERÄ° ğŸ§ 

## ğŸ“š Ä°Ã‡Ä°NDEKÄ°LER
1. [Embedding Nedir?](#embedding-nedir)
2. [NasÄ±l Ã‡alÄ±ÅŸÄ±r?](#nasÄ±l-Ã§alÄ±ÅŸÄ±r)
3. [Neden Ã–nemli?](#neden-Ã¶nemli)
4. [Mevcut Modeller](#mevcut-modeller)
5. [Model SeÃ§imi](#model-seÃ§imi)
6. [KullanÄ±m Ã–rnekleri](#kullanÄ±m-Ã¶rnekleri)
7. [Ã–nemli Notlar](#Ã¶nemli-notlar)

---

## ğŸ¤” EMBEDDING NEDÄ°R?

**Embedding** = Metni sayÄ±sal vektÃ¶rlere Ã§evirme iÅŸlemi

```python
# Ã–rnek
"kedi"      â†’ [0.2, 0.8, 0.1, 0.5, 0.3, ...] (768 boyutlu vektÃ¶r)
"kÃ¶pek"     â†’ [0.3, 0.7, 0.2, 0.4, 0.4, ...]
"bilgisayar"â†’ [0.9, 0.1, 0.8, 0.2, 0.1, ...]
```

### ğŸ¯ Anlamsal Benzerlik

VektÃ¶rler arasÄ± mesafe = Anlamsal yakÄ±nlÄ±k

```
Mesafe(kedi, kÃ¶pek)      = 0.15  âœ… YakÄ±n (her ikisi de hayvan)
Mesafe(kedi, bilgisayar) = 0.87  âŒ Uzak (ilgisiz)
```

---

## âš™ï¸ NASIL Ã‡ALIÅIR?

### AdÄ±m 1: Model YÃ¼kleme
```python
from langchain_community.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2"
)
```

### AdÄ±m 2: Metin â†’ VektÃ¶r DÃ¶nÃ¼ÅŸÃ¼mÃ¼
```python
text = "What is artificial intelligence?"
vector = embeddings.embed_query(text)

print(len(vector))  # 768 (vektÃ¶r boyutu)
print(vector[:5])   # [0.234, -0.123, 0.456, ...]
```

### AdÄ±m 3: Benzerlik Hesaplama
```python
# Cosine similarity ile karÅŸÄ±laÅŸtÄ±rma
from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity([vector1], [vector2])
```

---

## ğŸ¯ NEDEN Ã–NEMLÄ°?

### 1ï¸âƒ£ **Anlamsal Arama**
Kelime eÅŸleÅŸmesi deÄŸil, anlam eÅŸleÅŸmesi!

```
Soru: "How to make AI agents?"

âŒ Klasik Arama: "make" kelimesini arar
âœ… Embedding Arama: "create", "build", "develop" de bulur
```

### 2ï¸âƒ£ **RAG Sistemlerinin Temeli**
```
DÃ¶kÃ¼man â†’ Embedding â†’ Vector DB â†’ Arama â†’ Ä°lgili Chunk
```

### 3ï¸âƒ£ **Ã‡ok Dilli Destek**
```python
# TÃ¼rkÃ§e â†’ Ä°ngilizce eÅŸleÅŸme
"yapay zeka" â‰ˆ "artificial intelligence"
```

### 4ï¸âƒ£ **Verimli Depolama**
```
43,000 karakter metin â†’ 63 chunk â†’ 63 Ã— 768 sayÄ±
```

---

## ğŸ“¦ MEVCUT MODELLER

Bu klasÃ¶rdeki [embedding_models.py](embedding_models.py) dosyasÄ±nda 10 farklÄ± model var:

### ğŸ¥‡ EN POPÃœLER MODELLER

#### 1. HuggingFace Embeddings (Ãœcretsiz) â­
```python
from langchain_community.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2"
)
```

**Avantajlar:**
- âœ… Tamamen Ã¼cretsiz
- âœ… Yerel Ã§alÄ±ÅŸÄ±r (gizlilik)
- âœ… Ä°nternet gerekmez (model indirildikten sonra)

**Dezavantajlar:**
- âŒ Ä°lk kullanÄ±mda model indirme sÃ¼resi
- âŒ RAM kullanÄ±r (~1-2GB)

**PopÃ¼ler Modeller:**
- `all-mpnet-base-v2` â†’ Dengeli (768 boyut)
- `all-MiniLM-L6-v2` â†’ HÄ±zlÄ± (384 boyut)
- `paraphrase-multilingual-MiniLM-L12-v2` â†’ TÃ¼rkÃ§e destekli
- `BAAI/bge-large-en-v1.5` â†’ En iyi doÄŸruluk (1024 boyut)

---

#### 2. OpenAI Embeddings (Ãœcretli)
```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",  # veya "text-embedding-3-large"
    api_key="your-api-key"
)
```

**Avantajlar:**
- âœ… En iyi kalite
- âœ… Ã‡ok hÄ±zlÄ±
- âœ… RAM kullanmaz

**Dezavantajlar:**
- âŒ Ãœcretli (~$0.02 per 1M token)
- âŒ Ä°nternet gerekir
- âŒ Gizlilik endiÅŸeleri

---

#### 3. Cohere Embeddings (Ãœcretli)
```python
from langchain_community.embeddings import CohereEmbeddings

embeddings = CohereEmbeddings(
    model="embed-multilingual-v3.0",  # TÃ¼rkÃ§e destekli!
    cohere_api_key="your-api-key"
)
```

**Ã–ne Ã‡Ä±kan Ã–zellik:** Ã‡ok dilli destek (100+ dil, TÃ¼rkÃ§e dahil!)

---

#### 4. Ollama Embeddings (Yerel/Ãœcretsiz)
```python
from langchain_community.embeddings import OllamaEmbeddings

embeddings = OllamaEmbeddings(
    model="llama2",
    base_url="http://localhost:11434"
)
```

**Ã–nce Ollama kurulumu gerekir:**
```bash
# Mac
brew install ollama

# Model indirme
ollama pull llama2
```

---

## ğŸ¯ MODEL SEÃ‡Ä°MÄ°

### KullanÄ±m SenaryolarÄ±na GÃ¶re:

| Senaryo | Ã–nerilen Model | Neden? |
|---------|---------------|---------|
| ğŸ“ **Ã–ÄŸrenme/Prototip** | HuggingFace `all-mpnet-base-v2` | Ãœcretsiz, kolay baÅŸlangÄ±Ã§ |
| ğŸš€ **Production (Kalite)** | OpenAI `text-embedding-3-large` | En iyi doÄŸruluk |
| ğŸ’° **Production (BÃ¼tÃ§e)** | HuggingFace `BAAI/bge-large-en-v1.5` | Ãœcretsiz + iyi kalite |
| âš¡ **HÄ±z Ã–ncelikli** | HuggingFace `all-MiniLM-L6-v2` | KÃ¼Ã§Ã¼k, hÄ±zlÄ± |
| ğŸŒ **TÃ¼rkÃ§e Destek** | Cohere `embed-multilingual-v3.0` | 100+ dil |
| ğŸ”’ **Gizlilik/GDPR** | HuggingFace veya Ollama | Yerel Ã§alÄ±ÅŸÄ±r |
| â˜ï¸ **Cloud Native** | OpenAI veya Cohere | Managed service |

---

### KarÅŸÄ±laÅŸtÄ±rma Tablosu:

| Ã–zellik | HuggingFace | OpenAI | Cohere | Ollama |
|---------|-------------|---------|---------|---------|
| **Ãœcret** | Ãœcretsiz | Ãœcretli | Ãœcretli | Ãœcretsiz |
| **Kalite** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **HÄ±z** | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **Kurulum** | Kolay | Ã‡ok Kolay | Ã‡ok Kolay | Orta |
| **Ä°nternet** | Ä°lk kez | Her zaman | Her zaman | HayÄ±r |
| **Gizlilik** | YÃ¼ksek | DÃ¼ÅŸÃ¼k | DÃ¼ÅŸÃ¼k | YÃ¼ksek |
| **RAM KullanÄ±mÄ±** | 1-2GB | 0GB | 0GB | 1-2GB |
| **TÃ¼rkÃ§e** | BazÄ± modeller | Var | MÃ¼kemmel | Model'e gÃ¶re |

---

## ğŸ’» KULLANIM Ã–RNEKLERÄ°

### Ã–rnek 1: Tek Metin Embedding
```python
from langchain_community.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2"
)

# Tek metin
text = "What is machine learning?"
vector = embeddings.embed_query(text)

print(f"VektÃ¶r boyutu: {len(vector)}")
print(f"Ä°lk 5 deÄŸer: {vector[:5]}")
```

**Ã‡Ä±ktÄ±:**
```
VektÃ¶r boyutu: 768
Ä°lk 5 deÄŸer: [0.234, -0.123, 0.456, 0.789, -0.321]
```

---

### Ã–rnek 2: Ã‡oklu Metin Embedding
```python
texts = [
    "Machine learning is a subset of AI",
    "Deep learning uses neural networks",
    "Python is a programming language"
]

vectors = embeddings.embed_documents(texts)

print(f"Toplam vektÃ¶r sayÄ±sÄ±: {len(vectors)}")
print(f"Her vektÃ¶r boyutu: {len(vectors[0])}")
```

---

### Ã–rnek 3: Benzerlik Hesaplama
```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

text1 = "artificial intelligence"
text2 = "machine learning"
text3 = "cooking recipe"

v1 = embeddings.embed_query(text1)
v2 = embeddings.embed_query(text2)
v3 = embeddings.embed_query(text3)

sim_1_2 = cosine_similarity([v1], [v2])[0][0]
sim_1_3 = cosine_similarity([v1], [v3])[0][0]

print(f"AI â†” ML: {sim_1_2:.3f}")      # YÃ¼ksek (ilgili)
print(f"AI â†” Cooking: {sim_1_3:.3f}") # DÃ¼ÅŸÃ¼k (ilgisiz)
```

**Ã‡Ä±ktÄ±:**
```
AI â†” ML: 0.856      âœ… YÃ¼ksek benzerlik
AI â†” Cooking: 0.234 âŒ DÃ¼ÅŸÃ¼k benzerlik
```

---

### Ã–rnek 4: RAG'de KullanÄ±m
```python
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

# Embedding model
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2"
)

# Vector store oluÅŸturma
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory="./chroma_db"
)

# Arama
results = vectorstore.similarity_search("What is task decomposition?", k=3)
```

---

## âš ï¸ Ã–NEMLÄ° NOTLAR

### 1ï¸âƒ£ Model DeÄŸiÅŸtirirken Dikkat!

âŒ **YANLIÅ:**
```python
# Ä°lk kez
embeddings = HuggingFaceEmbeddings(model_name="all-mpnet-base-v2")
vectorstore = Chroma.from_documents(docs, embeddings)

# Sonra model deÄŸiÅŸti
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
vectorstore = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)
# âŒ HATA! Boyutlar uyumsuz (768 vs 384)
```

âœ… **DOÄRU:**
```python
# Model deÄŸiÅŸtirdiyseniz database'i yeniden oluÅŸturun
import shutil
shutil.rmtree("./chroma_db")  # Eski DB'yi sil

# Yeni model ile yeniden oluÅŸtur
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
vectorstore = Chroma.from_documents(docs, embeddings, persist_directory="./chroma_db")
```

---

### 2ï¸âƒ£ VektÃ¶r BoyutlarÄ±

FarklÄ± modeller farklÄ± boyutlar Ã¼retir:

| Model | Boyut |
|-------|-------|
| `all-mpnet-base-v2` | 768 |
| `all-MiniLM-L6-v2` | 384 |
| `BAAI/bge-large-en-v1.5` | 1024 |
| `text-embedding-3-small` (OpenAI) | 1536 |
| `text-embedding-3-large` (OpenAI) | 3072 |

**Kural:** AynÄ± database iÃ§in hep aynÄ± modeli kullanÄ±n!

---

### 3ï¸âƒ£ Ä°lk Ã‡alÄ±ÅŸtÄ±rma YavaÅŸ Olabilir

```python
# Ä°lk kez
embeddings = HuggingFaceEmbeddings(model_name="all-mpnet-base-v2")
# â³ Model indiriliyor... (~400MB, 1-2 dakika)

# Ä°kinci kez
embeddings = HuggingFaceEmbeddings(model_name="all-mpnet-base-v2")
# âš¡ HÄ±zlÄ±! (cache'den yÃ¼kleniyor)
```

**Model cache konumu:**
```
~/.cache/huggingface/hub/
```

---

### 4ï¸âƒ£ RAM KullanÄ±mÄ±

```python
# KÃ¼Ã§Ã¼k model (az RAM)
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
# ~500MB RAM

# BÃ¼yÃ¼k model (fazla RAM)
embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-large-en-v1.5")
# ~2GB RAM
```

**SÄ±nÄ±rlÄ± RAM varsa:** OpenAI veya Cohere (cloud) kullanÄ±n

---

### 5ï¸âƒ£ TÃ¼rkÃ§e DesteÄŸi

**TÃ¼rkÃ§e iÃ§in Ã¶nerilen modeller:**

```python
# SeÃ§enek 1: Multilingual HuggingFace (Ãœcretsiz)
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

# SeÃ§enek 2: Cohere Multilingual (Ãœcretli, En Ä°yi)
embeddings = CohereEmbeddings(
    model="embed-multilingual-v3.0",
    cohere_api_key="your-key"
)
```

---

## ğŸ§ª TEST DOSYALARI

Bu klasÃ¶rde test dosyalarÄ±:

### [test_embedding_models.py](test_embedding_models.py)
2 farklÄ± modeli karÅŸÄ±laÅŸtÄ±rÄ±r:
```bash
python EMBEDDINGS/test_embedding_models.py
```

**Ã‡Ä±ktÄ±:**
- VektÃ¶r boyutlarÄ±
- Ä°ÅŸlem sÃ¼releri
- Performans karÅŸÄ±laÅŸtÄ±rmasÄ±

---

## ğŸ“š DAHA FAZLA BÄ°LGÄ°

### Kaynaklar:
- **HuggingFace Model Hub:** https://huggingface.co/models?pipeline_tag=sentence-similarity
- **Sentence Transformers:** https://www.sbert.net/
- **OpenAI Embeddings:** https://platform.openai.com/docs/guides/embeddings
- **Cohere Embeddings:** https://docs.cohere.com/docs/embeddings

### Ä°lgili Dosyalar:
- [embedding_models.py](embedding_models.py) - 10 farklÄ± model Ã¶rneÄŸi
- [test_embedding_models.py](test_embedding_models.py) - Model karÅŸÄ±laÅŸtÄ±rma testi
- `../RAG/basic_rag.py` - RAG implementasyonunda kullanÄ±m

---

## ğŸ“ Ã–ZET

âœ… **Embedding** = Metin â†’ SayÄ±sal vektÃ¶r dÃ¶nÃ¼ÅŸÃ¼mÃ¼
âœ… **AmaÃ§** = Anlamsal benzerlik Ã¶lÃ§mek
âœ… **KullanÄ±m** = RAG sistemlerinde arama
âœ… **SeÃ§im** = Ä°htiyaca gÃ¶re (hÄ±z/kalite/maliyet)
âœ… **Dikkat** = Model deÄŸiÅŸince DB yenile!

---

## ğŸ’¡ HIZLI BAÅLANGIÃ‡

**En basit kurulum:**
```python
from langchain_community.embeddings import HuggingFaceEmbeddings

# Model oluÅŸtur
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2"
)

# Kullan
text = "Hello, world!"
vector = embeddings.embed_query(text)

print(f"âœ… Embedding oluÅŸturuldu! Boyut: {len(vector)}")
```

**Ä°yi Ã¶ÄŸrenmeler!** ğŸš€
